{
  "$schema": "../../../schema/2025-draft/neuro.schema.json",
  "metadata": {
    "model": {
      "name": "gpt_chat_assistant",
      "version": "3.5.1",
      "description": "Large language model optimized for conversational AI",
      "author": "AI Research Collective",
      "license": "MIT",
      "tags": ["gpt", "chat", "conversational", "large-language-model"],
      "modalities": {
        "inputs": ["text"],
        "outputs": ["text"]
      },
      "ui": {
        "display_name": "GPT Chat Assistant",
        "description": "An intelligent conversational AI that can help with a wide variety of tasks",
        "icon": "https://assets.airc.org/models/chat-gpt.svg", 
        "colors": {
          "light": {
            "primary": "#10A37F",
            "secondary": "#1A7F64"
          },
          "dark": {
            "primary": "#26D0CE",
            "secondary": "#20B2AA"
          }
        },
        "prompting": {
          "phrases": {
            "required": "You are a helpful assistant. ",
            "recommended": [
              "Please think step by step:",
              "Be concise and clear:",
              "If you're unsure, say so:",
              "Provide examples when helpful:"
            ]
          }
        }
      }
    }
  },
  "inputs": [
    {
      "name": "conversation_history",
      "description": "Previous conversation context",
      "shape": [2048],
      "dtype": "int32"
    },
    {
      "name": "user_message",
      "description": "Current user input message",
      "shape": [512],
      "dtype": "int32"
    }
  ],
  "outputs": [
    {
      "name": "response",
      "description": "Generated response from the assistant",
      "shape": [1024],
      "dtype": "int32",
      "value": "@{chat_model}"
    }
  ],
  "constants": [
    {
      "name": "encoder_layers",
      "type": "scalar",
      "value": 24
    },
    {
      "name": "hidden_size",
      "type": "scalar",
      "value": 1536
    },
    {
      "name": "num_attention_heads",
      "type": "scalar",
      "value": 16
    },
    {
      "name": "generator_layers",
      "type": "scalar",
      "value": 12
    }
  ],
  "definitions": [
    {
      "name": "chat_model",
      "type": "sequential",
      "arguments": [
        {"name": "context", "type": "tensor"},
        {"name": "message", "type": "tensor"}
      ],
      "subgraph": [
        {
          "name": "context_encoder",
          "type": "transformer",
          "arguments": ["@{inputs.context}"],
          "attributes": {
            "num_layers": "@{constants/encoder_layers}",
            "hidden_size": "@{constants/hidden_size}",
            "num_heads": "@{constants/num_attention_heads}"
          }
        },
            {
              "name": "message_encoder", 
              "type": "transformer",
              "arguments": ["@{inputs.message}"],
              "attributes": {
                "num_layers": "@{constants/encoder_layers}",
                "hidden_size": "@{constants/hidden_size}",
                "num_heads": "@{constants/num_attention_heads}"
              }
            },
            {
              "name": "fusion",
              "type": "cross_attention",
              "arguments": ["@{context_encoder}", "@{message_encoder}"],
              "attributes": {
                "num_heads": "@{constants/num_attention_heads}",
                "hidden_size": "@{constants/hidden_size}"
              }
            },
            {
              "name": "response_generator",
              "type": "transformer",
              "arguments": ["@{./fusion}"],
              "attributes": {
                "num_layers": "@{constants/generator_layers}",
                "hidden_size": "@{constants/hidden_size}",
                "num_heads": "@{constants/num_attention_heads}",
                "generation_mode": "autoregressive"
              }
            }
          ],
      "outputs": [
        {
          "name": "response",
          "description": "Generated response from the chat model",
          "source": "@{response_generator}"
        }
      ]
    }
  ],
  "export": [
    {
      "name": "chat_model",
      "type": "chat_model",
      "arguments": ["@{inputs.conversation_history}", "@{inputs.user_message}"]
    }
  ]
}
