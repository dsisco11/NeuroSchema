{
  "$schema": "../../schema/2025-draft/neuro.schema.json",
  "metadata": {
    "model": {
      "name": "multimodal_classifier",
      "version": "2.0.0",
      "description": "A multimodal model that combines text and image encoders for classification",
      "author": "NeuroFormat Team",
      "license": "MIT",
      "tags": ["multimodal", "classification", "imports", "example"],
      "modalities": {
        "inputs": ["text", "vision"],
        "outputs": ["tabular"]
      }
    }
  },
  "imports": [
    {
      "name": "text_encoder",
      "type": "neuro",
      "path": "./encoders/bert_base.neuro.json"
    },
    {
      "name": "image_encoder",
      "type": "neuro",
      "path": "./encoders/vision_transformer.neuro.json"
    },
    {
      "name": "pretrained_weights",
      "type": "safetensors",
      "path": "./weights/multimodal_v2.safetensors"
    },
    {
      "name": "config",
      "type": "neuro",
      "path": "./config/model_config.neuro.json"
    }
  ],
  "inputs": [
    {
      "name": "text_tokens",
      "description": "Tokenized text input",
      "shape": [512],
      "dtype": "int32"
    },
    {
      "name": "image",
      "description": "Preprocessed image tensor",
      "shape": [3, 224, 224],
      "dtype": "float32"
    }
  ],
  "outputs": [
    {
      "name": "classification_logits",
      "description": "Classification scores for 1000 classes",
      "shape": [1000],
      "dtype": "float32"
    },
    {
      "name": "attention_weights",
      "description": "Cross-modal attention weights",
      "shape": [512, 196],
      "dtype": "float32"
    }
  ],
  "constants": [
    {
      "name": "text_hidden_size",
      "type": "scalar",
      "value": "@{text_encoder:constants/hidden_size}"
    },
    {
      "name": "image_feature_dim",
      "type": "scalar",
      "value": "@{image_encoder:constants/feature_dim}"
    },
    {
      "name": "fusion_dim",
      "type": "scalar",
      "value": "@{config:constants/fusion_dimension}"
    },
    {
      "name": "num_classes",
      "type": "scalar",
      "value": "@{config:constants/output_classes}"
    }
  ],
  "definitions": [
    {
      "name": "cross_attention_fusion",
      "type": "sequential",
      "arguments": [
        { "name": "text_features", "type": "tensor" },
        { "name": "image_features", "type": "tensor" }
      ],
      "attributes": {
        "text_dim": "@{text_encoder:constants/hidden_size}",
        "image_dim": "@{image_encoder:constants/feature_dim}",
        "output_dim": "@{config:constants/fusion_dimension}"
      },
      "subgraph": [
        {
          "name": "text_projection",
          "type": "linear",
          "arguments": ["@{inputs.text_features}"],
          "weights": "@{pretrained_weights/text_proj_weight}",
          "bias": "@{pretrained_weights/text_proj_bias}",
          "attributes": {
            "in_features": "@{text_encoder:constants/hidden_size}",
            "out_features": "@{config:constants/fusion_dimension}"
          }
        },
            {
              "name": "image_projection",
              "type": "linear",
              "arguments": ["@{inputs.image_features}"],
              "weights": "@{pretrained_weights/image_proj_weight}",
              "bias": "@{pretrained_weights/image_proj_bias}",
              "attributes": {
                "in_features": "@{image_encoder:constants/feature_dim}",
                "out_features": "@{config:constants/fusion_dimension}"
              }
            },
            {
              "name": "cross_attention",
              "type": "config:definitions/multihead_attention",
              "arguments": ["@{text_projection}", "@{image_projection}"],
              "weights": "@{pretrained_weights/attention_weights}",
              "attributes": {
                "num_heads": "@{config:constants/attention_heads}",
                "embed_dim": "@{config:constants/fusion_dimension}"
              }
            },
            {
              "name": "fusion_output",
              "type": "add",
              "arguments": ["@{text_projection}", "@{cross_attention}"]
            }
          ],
      "outputs": [
        {
          "name": "fused_representation",
          "description": "Cross-attention fused text and image features",
          "source": "@{fusion_output}"
        }
      ]
    },
    {
      "name": "classification_head",
      "type": "sequential",
      "arguments": [{ "name": "fused_features", "type": "tensor" }],
      "attributes": {
        "input_dim": "@{config:constants/fusion_dimension}",
        "output_dim": "@{config:constants/output_classes}"
      },
      "subgraph": [
        {
          "name": "dropout",
          "type": "dropout",
          "arguments": ["@{inputs.fused_features}"],
          "attributes": {
            "p": "@{config:constants/dropout_rate}"
          }
        },
        {
          "name": "classifier",
          "type": "linear",
          "arguments": ["@{./dropout}"],
          "weights": "@{pretrained_weights/classifier_weight}",
          "bias": "@{pretrained_weights/classifier_bias}",
          "attributes": {
            "in_features": "@{config:constants/fusion_dimension}",
            "out_features": "@{config:constants/output_classes}"
          }
        }
      ],
      "outputs": [
        {
          "name": "logits",
          "description": "Classification logits for each class",
          "source": "@{classifier}"
        }
      ]
    }
  ],
  "export": [
    {
      "name": "text_features",
      "type": "text_encoder",
      "arguments": ["@{inputs.text_tokens}"]
    },
    {
      "name": "image_features",
      "type": "image_encoder",
      "arguments": ["@{inputs.image}"]
    },
    {
      "name": "fused_features",
      "type": "cross_attention_fusion",
      "arguments": ["@{./text_features}", "@{./image_features}"]
    },
    {
      "name": "classification_logits",
      "type": "classification_head",
      "arguments": ["@{inputs.fused_features}"]
    },
    {
      "name": "attention_weights",
      "type": "config:definitions/attention_extractor",
      "arguments": ["@{inputs.fused_features}"]
    }
  ]
}
